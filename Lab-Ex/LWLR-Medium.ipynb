{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4538e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(8)\n",
    "X = np.random.randn(1000,1)\n",
    "y = 2*(X**3) + 10 + 4.6*np.random.randn(1000,1)\n",
    "\n",
    "\n",
    "\n",
    "# Weight Matrix in code. It is a diagonal matrix.\n",
    "def wm(point, X, tau): \n",
    "    \n",
    "  # tau --> bandwidth\n",
    "  # X --> Training data.\n",
    "  # point --> the x where we want to make the prediction.\n",
    "    \n",
    "  # m is the No of training examples .\n",
    "    m = X.shape[0] \n",
    "    \n",
    "  # Initialising W as an identity matrix.\n",
    "    w = np.mat(np.eye(m)) \n",
    "    \n",
    "  # Calculating weights for all training examples [x(i)'s].\n",
    "    for i in range(m): \n",
    "        xi = X[i] \n",
    "        d = (-2 * tau * tau) \n",
    "        w[i, i] = np.exp(np.dot((xi-point), (xi-point).T)/d) \n",
    "        \n",
    "    return w\n",
    "\n",
    "\n",
    "def predict(X, y, point, tau): \n",
    "    \n",
    "   # m = number of training examples. \n",
    "    m = X.shape[0] \n",
    "    \n",
    "   # Appending a cloumn of ones in X to add the bias term.\n",
    "## # Just one parameter: theta, that's why adding a column of ones        #### to X and also adding a 1 for the point where we want to          #### predict. \n",
    "    X_ = np.append(X, np.ones(m).reshape(m,1), axis=1) \n",
    "    \n",
    "   # point is the x where we want to make the prediction. \n",
    "    point_ = np.array([point, 1]) \n",
    "    \n",
    "   # Calculating the weight matrix using the wm function we wrote      #  # earlier. \n",
    "    w = wm(point_, X_, tau) \n",
    "    \n",
    "  # Calculating parameter theta using the formula.\n",
    "    theta = np.linalg.pinv(X_.T*(w * X_))*(X_.T*(w * y)) \n",
    "    \n",
    "  # Calculating predictions.  \n",
    "    pred = np.dot(point_, theta) \n",
    "    \n",
    "   # Returning the theta and predictions \n",
    "    return theta, pred\n",
    "\n",
    "\n",
    "def plot_predictions(X, y, tau, nval):\n",
    "   # X --> Training data. \n",
    "   # y --> Output sequence.\n",
    "   # nval --> number of values/points for which we are going to\n",
    "   # predict.\n",
    "   # tau --> the bandwidth.     \n",
    "    # The values for which we are going to predict.\n",
    "   # X_test includes nval evenly spaced values in the domain of X.\n",
    "    X_test = np.linspace(-3, 3, nval) \n",
    "    \n",
    "   # Empty list for storing predictions. \n",
    "    preds = [] \n",
    "    \n",
    "   # Predicting for all nval values and storing them in preds. \n",
    "    for point in X_test: \n",
    "        theta, pred = predict(X, y, point, tau) \n",
    "        preds.append(pred)\n",
    "        \n",
    "   # Reshaping X_test and preds\n",
    "    X_test = np.array(X_test).reshape(nval,1)\n",
    "    preds = np.array(preds).reshape(nval,1)\n",
    "    \n",
    "   # Plotting \n",
    "    plt.plot(X, y, 'b.')\n",
    "    plt.plot(X_test, preds, 'r.') # Predictions in red color.\n",
    "    plt.show()\n",
    "plot_predictions(X, y, 0.08, 100)\n",
    "\n",
    "\n",
    "\n",
    "# When to use Locally Weighted Linear Regression?\n",
    "# When n (number of features) is small.\n",
    "# If you donâ€™t want to think about what features to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
