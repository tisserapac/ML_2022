{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Anjana Tissera\"\n",
    "ID = \"st123459\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06: Generative classifiers: Naive Bayes\n",
    "\n",
    "As discussed in class, a Naive Bayes classifier works as follows:\n",
    "$$\\begin{eqnarray}\n",
    "p(y \\mid \\mathbf{x} ; \\theta) & = & \\frac{p(\\mathbf{x} \\mid y ; \\theta) p(y ; \\theta)}{p(\\mathbf{x} ; \\theta)} \\\\\n",
    "& \\propto & p(\\mathbf{x} \\mid y ; \\theta) p(y ; \\theta) \\\\\n",
    "& \\approx & p(y ; \\theta) \\prod_j p(x_j \\mid y ; \\theta)\n",
    "\\end{eqnarray}$$\n",
    "We will use Naive Bayes to perform diabetes diagnosis and text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Diabetes classification\n",
    "\n",
    "In this example we predict wheter a patient with specific diagnostic measurements has diabetes or not. As the features are\n",
    "continuous, we will model the conditional probabilities\n",
    "$p(x_j \\mid y ; \\theta)$ as univariate Gaussians with mean $\\mu_{j,y}$ and standard deviation $\\sigma_{j,y}$.\n",
    "\n",
    "The data are originally from the U.S. National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) and are available\n",
    "from [Kaggle](https://www.kaggle.com/uciml/pima-indians-diabetes-database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data manipulation\n",
    "\n",
    "First we have some functions to read the dataset, split it into train and test, and partition it according to target class ($y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "def loadCsv(filename):\n",
    "    data_raw = pd.read_csv(filename)\n",
    "    headers = data_raw.columns\n",
    "    dataset = data_raw.values\n",
    "    return dataset, headers\n",
    "\n",
    "# Split dataset into test and train with given ratio\n",
    "def splitDataset(test_size,*arrays,**kwargs):\n",
    "    return train_test_split(*arrays,test_size=test_size,**kwargs)\n",
    "\n",
    "# Separate training data according to target class\n",
    "# Return key value pairs array in which keys are possible target variable values\n",
    "# and values are the data records.\n",
    "\n",
    "def data_split_byClass(dataset):\n",
    "    Xy = {}\n",
    "    for i in range(len(dataset)):\n",
    "        datapair = dataset[i]\n",
    "        # datapair[-1] (the last column) is the target class for this record.\n",
    "        # Check if we already have this value as a key in the return array\n",
    "        if (datapair[-1] not in Xy):\n",
    "            # Add class as key\n",
    "            Xy[datapair[-1]] = []\n",
    "        # Append this record to array of records for this class key\n",
    "        Xy[datapair[-1]].append(datapair)\n",
    "    return Xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "Next we have some functions used for training the model. Parameters include mean and standard deviation, used\n",
    "to partition numerical variables into categorical variables, as well as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of a Gaussian are its mean and standard deviation\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "# Calculate Gaussian parameters mu and sigma for each attribute over a dataset\n",
    "\n",
    "def get_gaussian_parameters(X,y):\n",
    "    parameters = {}\n",
    "    unique_y = np.unique(y)\n",
    "    for uy in unique_y:\n",
    "        mean = np.mean(X[y==uy],axis=0)\n",
    "        std = np.std(X[y==uy],axis=0)\n",
    "        py = y[y==uy].size/y.size\n",
    "        parameters[uy] = {'prior':py,'mean':mean,'std':std}\n",
    "    return parameters, unique_y\n",
    "\n",
    "def calculateProbability(x, mu, sigma):\n",
    "    sigma = np.diag(sigma**2)\n",
    "    x = x.reshape(-1,1)\n",
    "    mu = mu.reshape(-1,1)\n",
    "    exponent = np.exp(-1/2*(x-mu).T@np.linalg.inv(sigma)@(x-mu))\n",
    "    return ((1/(np.sqrt(((2*np.pi)**x.size)*np.linalg.det(sigma))))*exponent)[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing\n",
    "\n",
    "Next some functions for testing the model on a test set and computing its accuracy. Note that we assume\n",
    "$$ p(y \\mid \\mathbf{x} ; \\theta) \\propto p(\\mathbf{x} \\mid y ; \\theta), $$\n",
    "which means we assume that the priors $p(y)$ are equal for each possible value of $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class conditional probabilities for given input data vector\n",
    "\n",
    "def predict_one(x,parameters,unique_y,prior = True):\n",
    "    probabilities = []\n",
    "    for key in parameters.keys():\n",
    "        probabilities.append(calculateProbability(x,parameters[key]['mean'],parameters[key]['std'])*(parameters[key]['prior']**(float(prior))))\n",
    "    probabilities = np.array(probabilities)\n",
    "    return unique_y[np.argmax(probabilities)]\n",
    "\n",
    "def getPredictions(X, parameters, unique_y,prior=True):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        predictions.append(predict_one(X[i],parameters,unique_y,prior))\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Get accuracy for test set\n",
    "\n",
    "def getAccuracy(y, y_pred):\n",
    "    correct = len(y[y==y_pred])\n",
    "    return correct/y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "\n",
    "Here we load the diabetes dataset, split it into training and test data, train a Gaussian NB model, and test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 768 Train = 460 Test = 308\n",
      "Accuracy with Prior = 0.7337662337662337\n",
      "Accuracy without Prior = 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "filename = 'diabetes.csv'\n",
    "dataset, headers = loadCsv(filename)\n",
    "#print(headers)\n",
    "#print(np.array(dataset)[0:5,:])\n",
    "\n",
    "# Split into training and test\n",
    "\n",
    "X_train,X_test,y_train,y_test = splitDataset(0.4,dataset[:,:-1],dataset[:,-1])\n",
    "print(\"Total =\",len(dataset),\"Train =\", len(X_train),\"Test =\",len(X_test))\n",
    "\n",
    "# Train model\n",
    "\n",
    "parameters, unique_y = get_gaussian_parameters(X_train,y_train)\n",
    "prediction = getPredictions(X_test,parameters,unique_y)\n",
    "print(\"Accuracy with Prior =\",getAccuracy(y_test,prediction))\n",
    "\n",
    "# Test model\n",
    "\n",
    "prediction = getPredictions(X_test,parameters,unique_y,prior = False)\n",
    "print(\"Accuracy without Prior =\",getAccuracy(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0bcbc8407fdfb3f7d96cc07ad4d3124",
     "grade": false,
     "grade_id": "cell-9a740adb2ea13611",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###  Exercise In lab / take home work (20 points)\n",
    "\n",
    "Find out the proportion of the records in your dataset are positive vs. negative.  Can we conclude that $p(y=1) = p(y=0)$? If not, add\n",
    "the priors $p(y=1)$ and $p(y=0)$ to your NB model. Does it improve the result?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cf1a770bb1ee9faa6961f202769b10e",
     "grade": true,
     "grade_id": "cell-c1a5f74a2d330b0c",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positive records:  0.3521739130434783\n",
      "Proportion of negative records:  0.6478260869565218\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "#Proportion of the records in the dataset that are positive vs. negative\n",
    "y_train_int = (y_train).astype(int)\n",
    "m_train = y_train_int.shape[0]\n",
    "prior_y_1 = np.count_nonzero(y_train_int == 1) / m_train\n",
    "prior_y_0 = np.count_nonzero(y_train_int == 0) / m_train \n",
    "\n",
    "print(\"Proportion of positive records: \", prior_y_1 )\n",
    "print(\"Proportion of negative records: \", prior_y_0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f416d2fceb4d17b1865da03585d6f44f",
     "grade": false,
     "grade_id": "cell-a32adf75650dfd55",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**Explain that you can conclude that $p(y=1) = p(y=0)$? If not, add\n",
    "the priors $p(y=1)$ and $p(y=0)$ to your NB model. Does it improve the result? (double click to explain)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "$p(y=1) = 0.3695652173913043$\n",
    "\n",
    "$p(y=0) = 0.6304347826086957$\n",
    "\n",
    "Therefore we cannot conclude that $p(y=1) = p(y=0)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the priors  𝑝(𝑦=1)  and  𝑝(𝑦=0)  to NB model.\n",
    "\n",
    "class GaussianNB:\n",
    "    def __init__(self, include_prior=True):\n",
    "        self.include_prior = include_prior\n",
    "        self.n_samples = 0\n",
    "        self.n_features = 0\n",
    "        self.n_classes = 0\n",
    "        self.mean = None\n",
    "        self.variance = None\n",
    "        self.priors = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.n_classes = len(np.unique(y))\n",
    "\n",
    "        self.mean = np.zeros((self.n_classes, self.n_features))\n",
    "        self.variance = np.zeros((self.n_classes, self.n_features))\n",
    "        self.priors = np.zeros(self.n_classes)\n",
    "\n",
    "        for c in range(self.n_classes):\n",
    "            X_c = X[y == c]\n",
    "\n",
    "            self.mean[c, :] = np.mean(X_c, axis=0)\n",
    "            self.variance[c, :] = np.var(X_c, axis=0)\n",
    "            self.priors[c] = X_c.shape[0] / self.n_samples\n",
    "            \n",
    "    def predict(self, X):\n",
    "        y_hat = [self._get_class_probability(x) for x in X]\n",
    "        return np.array(y_hat)\n",
    "    \n",
    "    def _get_class_probability(self, x):\n",
    "        posteriors = list()\n",
    "        for c in range(self.n_classes):\n",
    "            mean = self.mean[c]\n",
    "            variance = self.variance[c]\n",
    "            prior = self.priors[c]\n",
    "            likelihood = self._gaussian_density(x, mean, variance)\n",
    "            total_likelihood = np.prod(likelihood)\n",
    "            \n",
    "            if self.include_prior:\n",
    "                posterior = prior * total_likelihood\n",
    "            else:\n",
    "                posterior = total_likelihood\n",
    "            \n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        return np.argmax(posteriors)    \n",
    "    \n",
    "    def _gaussian_density(self, x, mean, var):\n",
    "        const = 1 / np.sqrt(var * 2 * np.pi)\n",
    "        proba = np.exp(-0.5 * ((x - mean) ** 2 / var))\n",
    "        return const * proba   \n",
    "    \n",
    "def get_gaussiannb_accuracy(y_true, y_hat):\n",
    "    return np.sum(y_true==y_hat) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 8) (308, 8) (460,) (308,)\n"
     ]
    }
   ],
   "source": [
    "# Setting X and y\n",
    "X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "        'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "\n",
    "y = df['Outcome']\n",
    "\n",
    "# Train, test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=999)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize X_train, X_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy without including priors:  0.7467532467532467\n"
     ]
    }
   ],
   "source": [
    "# Model without including prior\n",
    "gnb_no_prior = GaussianNB(include_prior=False)\n",
    "gnb_no_prior.fit(X_train, y_train)\n",
    "yhat_no_prior = gnb_no_prior.predict(X_test)\n",
    "print('Naive Bayes accuracy without including priors: ', get_gaussiannb_accuracy(y_test, yhat_no_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy with including priors:  0.7564935064935064\n"
     ]
    }
   ],
   "source": [
    "# Model without including prior\n",
    "gnb_with_prior = GaussianNB(include_prior=True)\n",
    "gnb_with_prior.fit(X_train, y_train)\n",
    "yhat_with_prior = gnb_with_prior.predict(X_test)\n",
    "print('Naive Bayes accuracy with including priors: ', get_gaussiannb_accuracy(y_test, yhat_with_prior))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Comparison of Gaussian Naive Bayes accuracy with and without priors include:\n",
    "\n",
    "|  | With Priors | Without Priors |\n",
    "| --- | --- | --- |\n",
    "| Accuracy | 0.7564935064935064 | 0.7467532467532467 |\n",
    "\n",
    "\n",
    "- From the above table we can see that when prior probabilities are inclded there is a small increase in the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Text classification\n",
    "\n",
    "This example has been adapted from a post by Jaya Aiyappan, available at\n",
    "[Analytics Vidhya](https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b#:~:text=The%20Naive%20Bayes%20classifier%20is,time%20and%20less%20training%20data).\n",
    "\n",
    "We will generate a small dataset of sentences that are classified as either \"statements\" or \"questions.\"\n",
    "\n",
    "We will assume that occurance and placement of words within a sentence is independent of each other\n",
    "(i.e., the features are conditionally independent given $y$). So the sentence \"this is my book\" is the same as \"is this my book.\"\n",
    "We will treat words as case insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             sentence      class\n",
      "0               This is my novel book  statement\n",
      "1  this book has more than one author  statement\n",
      "2                     is this my book   question\n",
      "3                     They are novels  statement\n",
      "4             have you read this book   question\n",
      "5            who is the novels author   question\n",
      "6             what are the characters   question\n",
      "7       This is how I bought the book  statement\n",
      "8         I like fictional characters  statement\n",
      "9          what is your favorite book   question\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "                        sentence      class\n",
      "0               this is the book  statement\n",
      "1  who are the novels characters   question\n",
      "2             is this the author   question\n",
      "3                  I like apples       None\n"
     ]
    }
   ],
   "source": [
    "# Generate text data for two classes, \"statement\" and \"question\"\n",
    "\n",
    "text_train = [['This is my novel book', 'statement'],\n",
    "              ['this book has more than one author', 'statement'],\n",
    "              ['is this my book', 'question'],\n",
    "              ['They are novels', 'statement'],\n",
    "              ['have you read this book', 'question'],\n",
    "              ['who is the novels author', 'question'],\n",
    "              ['what are the characters', 'question'],\n",
    "              ['This is how I bought the book', 'statement'],\n",
    "              ['I like fictional characters', 'statement'],\n",
    "              ['what is your favorite book', 'question']]\n",
    "\n",
    "text_test = [['this is the book', 'statement'], \n",
    "             ['who are the novels characters', 'question'], \n",
    "             ['is this the author', 'question'],\n",
    "            ['I like apples']]\n",
    "\n",
    "# Load training and test data into pandas data frames\n",
    "\n",
    "training_data = pd.DataFrame(text_train, columns= ['sentence', 'class'])\n",
    "print(training_data)\n",
    "print('\\n------------------------------------------\\n')\n",
    "testing_data = pd.DataFrame(text_test, columns= ['sentence', 'class'])\n",
    "print(testing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition training data by class\n",
    "\n",
    "stmt_docs = [train['sentence'] for index,train in training_data.iterrows() if train['class'] == 'statement']\n",
    "question_docs = [train['sentence'] for index,train in training_data.iterrows() if train['class'] == 'question']\n",
    "all_docs = [train['sentence'] for index,train in training_data.iterrows()]\n",
    "\n",
    "# Get word frequencies for each sentence and class\n",
    "\n",
    "def get_words(text):\n",
    "    # Initialize word list\n",
    "    words = [];\n",
    "    # Loop through each sentence in input array\n",
    "    for text_row in text: \n",
    "        # Check the number of words. Assume each word is separated by a blank space\n",
    "        # so that the number of words is the number of blank spaces + 1\n",
    "        number_of_spaces = text_row.count(' ')\n",
    "        # loop through the sentence and get words between blank spaces.\n",
    "        for i in range(number_of_spaces):\n",
    "            # Check for for last word\n",
    "            words.append([text_row[:text_row.index(' ')].lower()])\n",
    "            text_row = text_row[text_row.index(' ')+1:]  \n",
    "            i = i + 1        \n",
    "        words.append([text_row])\n",
    "    return np.unique(words)\n",
    "\n",
    "# Get frequency of each word in each document\n",
    "\n",
    "def get_doc_word_frequency(words, text):  \n",
    "    word_freq_table = np.zeros((len(text),len(words)), dtype=int)\n",
    "    i = 0\n",
    "    for text_row in text:\n",
    "        # Insert extra space between each pair of words to prevent\n",
    "        # partial match of words\n",
    "        text_row_temp = ''\n",
    "        for idx, val in enumerate(text_row):\n",
    "            if val == ' ':\n",
    "                 text_row_temp = text_row_temp + '  '\n",
    "            else:\n",
    "                  text_row_temp = text_row_temp + val.lower()\n",
    "        text_row = ' ' + text_row_temp + ' '\n",
    "        j = 0\n",
    "        for word in words: \n",
    "            word = ' ' + word + ' '\n",
    "            freq = text_row.count(word)\n",
    "            word_freq_table[i,j] = freq\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    \n",
    "    return word_freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   are  author  book  bought  characters  fictional  has  how  i  is  like  \\\n",
      "0    0       0     1       0           0          0    0    0  0   1     0   \n",
      "1    0       1     1       0           0          0    1    0  0   0     0   \n",
      "2    1       0     0       0           0          0    0    0  0   0     0   \n",
      "3    0       0     1       1           0          0    0    1  1   1     0   \n",
      "4    0       0     0       0           1          1    0    0  1   0     1   \n",
      "\n",
      "   more  my  novel  novels  one  than  the  they  this  \n",
      "0     0   1      1       0    0     0    0     0     1  \n",
      "1     1   0      0       0    1     1    0     0     1  \n",
      "2     0   0      0       1    0     0    0     1     0  \n",
      "3     0   0      0       0    0     0    1     0     1  \n",
      "4     0   0      0       0    0     0    0     0     0  \n"
     ]
    }
   ],
   "source": [
    "# Get word frequencies for statement documents\n",
    "\n",
    "word_list_s = get_words(stmt_docs)\n",
    "word_freq_table_s = get_doc_word_frequency(word_list_s, stmt_docs)\n",
    "tdm_s = pd.DataFrame(word_freq_table_s, columns=word_list_s)\n",
    "print(tdm_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'are': 1, 'author': 1, 'book': 3, 'bought': 1, 'characters': 1, 'fictional': 1, 'has': 1, 'how': 1, 'i': 2, 'is': 2, 'like': 1, 'more': 1, 'my': 1, 'novel': 1, 'novels': 1, 'one': 1, 'than': 1, 'the': 1, 'they': 1, 'this': 3}\n"
     ]
    }
   ],
   "source": [
    "# Get word frequencies over all statement documents\n",
    "\n",
    "freq_list_s = word_freq_table_s.sum(axis=0) \n",
    "freq_s = dict(zip(word_list_s,freq_list_s))\n",
    "print(freq_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   are  author  book  characters  favorite  have  is  my  novels  read  the  \\\n",
      "0    0       0     1           0         0     0   1   1       0     0    0   \n",
      "1    0       0     1           0         0     1   0   0       0     1    0   \n",
      "2    0       1     0           0         0     0   1   0       1     0    1   \n",
      "3    1       0     0           1         0     0   0   0       0     0    1   \n",
      "4    0       0     1           0         1     0   1   0       0     0    0   \n",
      "\n",
      "   this  what  who  you  your  \n",
      "0     1     0    0    0     0  \n",
      "1     1     0    0    1     0  \n",
      "2     0     0    1    0     0  \n",
      "3     0     1    0    0     0  \n",
      "4     0     1    0    0     1  \n"
     ]
    }
   ],
   "source": [
    "# Get word frequencies for question documents\n",
    "\n",
    "word_list_q = get_words(question_docs)\n",
    "word_freq_table_q = get_doc_word_frequency(word_list_q, question_docs)\n",
    "tdm_q = pd.DataFrame(word_freq_table_q, columns=word_list_q)\n",
    "print(tdm_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'are': 1, 'author': 1, 'book': 3, 'characters': 1, 'favorite': 1, 'have': 1, 'is': 3, 'my': 1, 'novels': 1, 'read': 1, 'the': 2, 'this': 2, 'what': 2, 'who': 1, 'you': 1, 'your': 1}\n",
      "[1 1 3 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 3]\n",
      "[1 1 3 1 1 1 3 1 1 1 2 2 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Get word frequencies over all question documents\n",
    "\n",
    "freq_list_q = word_freq_table_q.sum(axis=0) \n",
    "freq_q = dict(zip(word_list_q,freq_list_q))\n",
    "print(freq_q)\n",
    "print(freq_list_s)\n",
    "print(freq_list_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of words for \"statement\" class \n",
      "\n",
      "{'are': 0.043478260869565216, 'author': 0.043478260869565216, 'book': 0.08695652173913043, 'bought': 0.043478260869565216, 'characters': 0.043478260869565216, 'fictional': 0.043478260869565216, 'has': 0.043478260869565216, 'how': 0.043478260869565216, 'i': 0.06521739130434782, 'is': 0.06521739130434782, 'like': 0.043478260869565216, 'more': 0.043478260869565216, 'my': 0.043478260869565216, 'novel': 0.043478260869565216, 'novels': 0.043478260869565216, 'one': 0.043478260869565216, 'than': 0.043478260869565216, 'the': 0.043478260869565216, 'they': 0.043478260869565216, 'this': 0.08695652173913043}\n",
      "------------------------------------------- \n",
      "\n",
      "Probability of words for \"question\" class \n",
      "\n",
      "{'are': 0.05128205128205128, 'author': 0.05128205128205128, 'book': 0.10256410256410256, 'characters': 0.05128205128205128, 'favorite': 0.05128205128205128, 'have': 0.05128205128205128, 'is': 0.10256410256410256, 'my': 0.05128205128205128, 'novels': 0.05128205128205128, 'read': 0.05128205128205128, 'the': 0.07692307692307693, 'this': 0.07692307692307693, 'what': 0.07692307692307693, 'who': 0.05128205128205128, 'you': 0.05128205128205128, 'your': 0.05128205128205128}\n"
     ]
    }
   ],
   "source": [
    "# Get word probabilities for statement class\n",
    "a = 1\n",
    "prob_s = []\n",
    "for count in freq_list_s:\n",
    "    #print(word, count)\n",
    "    prob_s.append((count+a)/(sum(freq_list_s)+len(freq_list_s)*a))\n",
    "#prob_s.append(a/(sum(freq_list_s)+len(freq_list_s)*a))\n",
    "    \n",
    "# Get word probabilities for question class\n",
    "\n",
    "prob_q = []\n",
    "for count in freq_list_q:\n",
    "    prob_q.append((count+a)/(sum(freq_list_q)+len(freq_list_q)*a))\n",
    "#prob_q.append(a/(sum(freq_list_q)+len(freq_list_q)*a))   \n",
    "    \n",
    "    \n",
    "print('Probability of words for \"statement\" class \\n')\n",
    "print(dict(zip(word_list_s, prob_s)))\n",
    "print('------------------------------------------- \\n')\n",
    "print('Probability of words for \"question\" class \\n')\n",
    "print(dict(zip(word_list_q, prob_q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prior for one class\n",
    "\n",
    "def prior(className):    \n",
    "    denominator = len(stmt_docs) + len(question_docs)\n",
    "    \n",
    "    if className == 'statement':\n",
    "        numerator =  len(stmt_docs)\n",
    "    else:\n",
    "        numerator =  len(question_docs)\n",
    "        \n",
    "    return np.divide(numerator,denominator)\n",
    "    \n",
    "# Calculate class conditional probability for a sentence\n",
    "    \n",
    "def classCondProb(sentence, className):\n",
    "    words = get_words(sentence)\n",
    "    prob = 1\n",
    "    for word in words:\n",
    "        if className == 'statement':\n",
    "            idx = np.where(word_list_s == word)\n",
    "            prob = prob * prob_s[np.array(idx)[0,0]]\n",
    "        else:\n",
    "            idx = np.where(word_list_q == word)\n",
    "            prob = prob * prob_q[np.array(idx)[0,0]]   \n",
    "    \n",
    "    return prob\n",
    "\n",
    "# Predict class of a sentence\n",
    "\n",
    "def predict(sentence):\n",
    "    prob_statement = classCondProb(sentence, 'statement') * prior('statement')\n",
    "    prob_question = classCondProb(sentence, 'question') * prior('question')\n",
    "    if  prob_statement > prob_question:\n",
    "        return 'statement'\n",
    "    else:\n",
    "        return 'question'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06f31d4f4657c9d7a61ca287b3a51c86",
     "grade": false,
     "grade_id": "cell-3b166fac02ec4711",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### In-lab exercise: Laplace smoothing\n",
    "\n",
    "Run the code below and figure out why it fails.\n",
    "\n",
    "When a word does not appear with a specific class in the training data, its class-conditional probability is 0, and we are unable to\n",
    "get a reasonable probability for that class.\n",
    "\n",
    "Research Laplace smoothing, and modify the code above to implement Laplace smoothing (setting the frequency of all words with frequency 0 to a frequency of 1).\n",
    "Run the modified code on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prediction for \"this is the book\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 1 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m test_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m([test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m index,test \u001b[38;5;129;01min\u001b[39;00m testing_data\u001b[38;5;241m.\u001b[39miterrows()])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGetting prediction for \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m test_docs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(sentence):\n\u001b[0;32m---> 31\u001b[0m     prob_statement \u001b[38;5;241m=\u001b[39m \u001b[43mclassCondProb\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatement\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m prior(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatement\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m     prob_question \u001b[38;5;241m=\u001b[39m classCondProb(sentence, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m*\u001b[39m prior(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m  prob_statement \u001b[38;5;241m>\u001b[39m prob_question:\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mclassCondProb\u001b[0;34m(sentence, className)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m className \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatement\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     20\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(word_list_s \u001b[38;5;241m==\u001b[39m word)\n\u001b[0;32m---> 21\u001b[0m     prob \u001b[38;5;241m=\u001b[39m prob \u001b[38;5;241m*\u001b[39m prob_s[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(word_list_q \u001b[38;5;241m==\u001b[39m word)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 1 with size 0"
     ]
    }
   ],
   "source": [
    "test_docs = list([test['sentence'] for index,test in testing_data.iterrows()])\n",
    "print('Getting prediction for \"%s\"' % test_docs[0])\n",
    "predict(test_docs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c92cc1750ff6519f167950df416dbad7",
     "grade": false,
     "grade_id": "cell-9d86c9d269d1a550",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.1 (10 points)\n",
    "\n",
    "Explain Why it failed and explain how to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a8b94cb831bb4a934e82d63cdf77be3",
     "grade": false,
     "grade_id": "cell-d424d31d1e17fd89",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Explanation here! (Double click to explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason for failure\n",
    "- The function get_words(text) expects a list of sentences as its input. If we pass a single string as the input since a string is literally a list of characters  get_words function treats each character of the string input as a word.\n",
    "- Then subsequently we try to find the class conditional probability of each character using the classCondProb() function which results in an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a281f0b0b151358f4dbbcbfb6adbd38",
     "grade": false,
     "grade_id": "cell-e17217b48752c1fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.2 (20 points)\n",
    "\n",
    "Modify your code and make it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrected code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prediction for \"this is the book\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'question'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs = list([test['sentence'] for index,test in testing_data.iterrows()])\n",
    "print('Getting prediction for \"%s\"' % test_docs[0])\n",
    "predict(list([test_docs[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e51fedc8aefb2614a7936134d6333f67",
     "grade": false,
     "grade_id": "cell-0722e2f212d3751c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Find words in question class, bu not in statement class\n",
    "not_in_statement = np.setdiff1d(word_list_q, word_list_s)\n",
    "\n",
    "# Find words in statement class, bu not in question class\n",
    "not_in_question = np.setdiff1d(word_list_s, word_list_q)\n",
    "\n",
    "# Increace the word frequencies in statement documents by 1\n",
    "freq_s_laplace = None\n",
    "freq_s_laplace = freq_s.copy()\n",
    "for word in freq_s_laplace:\n",
    "    freq_s_laplace[word] += 1\n",
    "\n",
    "# Add words in question class, bu not in statement class to freq_s_laplace with a frequency of 1\n",
    "for word in not_in_statement:\n",
    "    freq_s_laplace[word] = 1\n",
    "    \n",
    "# Increace the word frequencies in question documents by 1\n",
    "freq_q_laplace = None\n",
    "freq_q_laplace = freq_q.copy()\n",
    "for word in freq_q_laplace:\n",
    "    freq_q_laplace[word] += 1\n",
    "\n",
    "# Add words in statement class, bu not in question class to freq_q_laplace with a frequency of 1\n",
    "for word in not_in_question:\n",
    "    freq_q_laplace[word] = 1\n",
    "    \n",
    "# Calculate updated word probabilities  - statement class\n",
    "freq_s_values = list(freq_s_laplace.values())\n",
    "sum_freq_s_values = sum(freq_s_values)\n",
    "prob_s_laplace = {}\n",
    "for word in freq_s_laplace:\n",
    "    prob_s_laplace[word] = float(freq_s_laplace[word])/ sum_freq_s_values\n",
    "\n",
    "# Calculate updated word probabilities  - question class\n",
    "freq_q_values = list(freq_q_laplace.values())\n",
    "sum_freq_q_values = sum(freq_q_values)\n",
    "prob_q_laplace = {}\n",
    "for word in freq_q_laplace:\n",
    "    prob_q_laplace[word] = float(freq_q_laplace[word])/ sum_freq_q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class conditional probability for a sentence with Laplace smoothing\n",
    "def classCondProb_Laplace(sentence, className):\n",
    "    words = get_words(sentence)\n",
    "    prob = 1\n",
    "    for word in words:\n",
    "        if className == 'statement':\n",
    "            if word in prob_s_laplace:\n",
    "                prob = prob * prob_s_laplace[word]\n",
    "        else:\n",
    "            if word in prob_q_laplace:\n",
    "                prob = prob * prob_q_laplace[word] \n",
    "    \n",
    "    return prob\n",
    "\n",
    "# Predict class of a sentence with Laplace smoothing\n",
    "def predict(sentence):\n",
    "    prob_statement = classCondProb_Laplace(sentence, 'statement') * prior('statement')\n",
    "    prob_question = classCondProb_Laplace(sentence, 'question') * prior('question')\n",
    "    if  prob_statement > prob_question:\n",
    "        return 'statement'\n",
    "    else:\n",
    "        return 'question'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b12f4c8d6b4163d2f6cfe464b3ba62f3",
     "grade": true,
     "grade_id": "cell-c576e7ed4dd3046a",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prediction for this is the book\"\n",
      "statement\n",
      "Getting prediction for who are the novels characters\"\n",
      "question\n",
      "Getting prediction for is this the author\"\n",
      "statement\n",
      "Getting prediction for I like apples\"\n",
      "statement\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "# Test function: Do not remove\n",
    "test_docs = list([test['sentence'] for index,test in testing_data.iterrows()])\n",
    "\n",
    "for sentence in test_docs:\n",
    "    print('Getting prediction for %s\"' % sentence)\n",
    "    print(predict(sentence))\n",
    "    \n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prediction for \"this is the book\"\n",
      "question\n",
      "Getting prediction for \"who are the novels characters\"\n",
      "question\n",
      "Getting prediction for \"is this the author\"\n",
      "question\n",
      "Getting prediction for \"I like apples\"\n",
      "statement\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "# Test function: Do not remove\n",
    "test_docs = list([test['sentence'] for index,test in testing_data.iterrows()])\n",
    "\n",
    "for sentence in test_docs:\n",
    "    print('Getting prediction for \"%s\"' % sentence)\n",
    "    print(predict(list([sentence])))\n",
    "    \n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63a751b5f418dd7b04bf156032e8435f",
     "grade": false,
     "grade_id": "cell-12db07859804f68d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result**:\\\n",
    "Getting prediction for this is the book\"\\\n",
    "question\\\n",
    "Getting prediction for who are the novels characters\"\\\n",
    "question\\\n",
    "Getting prediction for is this the author\"\\\n",
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a3302658ee7212f23942b2d4d93e70c",
     "grade": false,
     "grade_id": "cell-2bc1a154cce1dd7a",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Take home exercise\n",
    "\n",
    "Find a more substantial text classification dataset, clean up the documents, and build your NB classifier. Write a brief report on your in-lab and take home exercises and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "- In this exercise I used the 'apple_twitter_sentiment_texts' dataset from Kaggle available at https://www.kaggle.com/datasets/seriousran/appletwittersentimenttexts.\n",
    "\n",
    "- This dataset look into the sentiment around Apple, based on tweets containing #AAPL, @apple, etc. Contributors were given a tweet and asked whether the user was positive(1), negative(-1), or neutral(0) about Apple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anjana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import operator\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to clean the dataset\n",
    "def data_clean(X):\n",
    "    data = X.copy()\n",
    "    char = '@'\n",
    "    data['text'] = data['text'].str.lower()\n",
    "    pattern1 = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+|#[a-zA-Z]+|$[a-zA-Z]+|@[a-zA-Z]+|[,.^_#$*%-;鶯椰~!?:]')\n",
    "    pattern2 = re.compile('rt')\n",
    "    for i in range(len(data['text'])):\n",
    "        data['text'][i] = \" \".join(word for word in data['text'][i].split(' ') if not word.startswith(char))\n",
    "        data['text'][i] = pattern1.sub('', data['text'][i])\n",
    "        data['text'][i] = pattern2.sub('', data['text'][i])\n",
    "        data['text'][i] = re.sub(r'[^A-Za-z ]+', '', data['text'][i])\n",
    "        \n",
    "    stop = stopwords.words('english')\n",
    "    data['text'] = data['text'].str.split()\n",
    "    data['text'] = data['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data.iloc[i] = \" \".join(\" \".join(l) for l in data.iloc[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesTextClassifier(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_messages = {}\n",
    "        self.log_class_priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.vocab = set()\n",
    "        self.y_classes = {}\n",
    "    \n",
    "    def _tokenize(self, text):\n",
    "        return re.split(\"\\W+\", text)\n",
    "    \n",
    "    def _get_word_counts(self, words):\n",
    "        word_counts = {}\n",
    "        for word in words:\n",
    "            word_counts[word] = word_counts.get(word, 0.0) + 1.0\n",
    "        return word_counts\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Reset attributes\n",
    "        self.num_messages = {}\n",
    "        self.log_class_priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.vocab = set()\n",
    "        self.y_classes = {}\n",
    "        n = len(X)\n",
    "        \n",
    "        self.y_classes = pd.Series(y).value_counts().to_dict()\n",
    "        for y_class in self.y_classes:\n",
    "            self.num_messages[y_class] = sum(1 for label in y if label == y_class)\n",
    "            self.log_class_priors[y_class] = math.log(self.num_messages[y_class] / n)\n",
    "            self.word_counts[y_class] = {}\n",
    "        \n",
    "        for x, y_val in zip(X, y):\n",
    "            if x == \"\": continue\n",
    "            c = y_val\n",
    "            counts = self._get_word_counts(self._tokenize(x))\n",
    "            for word, count in counts.items():\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab.add(word)\n",
    "                if word not in self.word_counts[c]:\n",
    "                    self.word_counts[c][word] = 0.0\n",
    "                self.word_counts[c][word] += count\n",
    "                \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for x in X:\n",
    "            class_score = {}\n",
    "            for y_class in self.y_classes:\n",
    "                class_score[y_class] = 0\n",
    "            if len(x.strip()) != 0:                \n",
    "                counts = self._get_word_counts(self._tokenize(x))\n",
    "                for word, _ in counts.items():\n",
    "                    if word not in self.vocab: continue                \n",
    "                    for y_class in self.y_classes:\n",
    "                        # add Laplace smoothing\n",
    "                        log_w_given_class = math.log( (self.word_counts[y_class].get(word, 0.0) + 1) / (self.num_messages[y_class] + len(self.vocab)) )\n",
    "                        class_score[y_class] += log_w_given_class \n",
    "            for y_class in self.y_classes:\n",
    "                class_score[y_class] += self.log_class_priors[y_class]\n",
    "            \n",
    "            result.append(max(class_score.items(), key=operator.itemgetter(1))[0])\n",
    "        np_result = np.array(result)\n",
    "        return np_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow. Yall needa step it up @Apple RT @heynyla:...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What Happened To Apple Inc?   http://t.co/FJEX...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank u @apple I can now compile all of the pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The oddly uplifting story of the Apple co-foun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@apple can i exchange my iphone for a differen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Wow. Yall needa step it up @Apple RT @heynyla:...         -1\n",
       "1  What Happened To Apple Inc?   http://t.co/FJEX...          0\n",
       "2  Thank u @apple I can now compile all of the pi...          1\n",
       "3  The oddly uplifting story of the Apple co-foun...          0\n",
       "4  @apple can i exchange my iphone for a differen...          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"apple-twitter-sentiment-texts.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    801\n",
       "-1    686\n",
       " 1    143\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Using the entire dataset (Classes are unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1141, 1) (489, 1) (1141,) (489,)\n"
     ]
    }
   ],
   "source": [
    "# Setting X and y\n",
    "X = data[['text']]\n",
    "\n",
    "y = data['sentiment']\n",
    "\n",
    "# Train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=999)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset and drop indexes\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning X_train\n",
    "X_train_cleaned = data_clean(X_train)\n",
    "\n",
    "# Converting X_train_cleaned and y_train to Numpy arrays\n",
    "X_train_cleaned_np = (X_train_cleaned.iloc[:,[0]].values).reshape((-1,))\n",
    "y_train_np = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training NaiveBayesTextClassifier\n",
    "nb = NaiveBayesTextClassifier()\n",
    "nb.fit(X_train_cleaned_np, y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning X_test\n",
    "X_test_cleaned = data_clean(X_test)\n",
    "\n",
    "# Converting X_train_cleaned and y_train to Numpy arrays\n",
    "X_test_cleaned_np = (X_test_cleaned.iloc[:,[0]].values).reshape((-1,))\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "# Predictions for X_test\n",
    "y_predict = nb.predict(X_test_cleaned_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayesTextClassifierAccuracy prediction accuracy - unbalanced dataset:  0.8077709611451943\n"
     ]
    }
   ],
   "source": [
    "def getNaiveBayesTextClassifierAccuracy(y, y_predict):\n",
    "    acc = (y_predict == y).astype(int).sum() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "test_acc = getNaiveBayesTextClassifierAccuracy(y_test_np, y_predict)\n",
    "print(\"NaiveBayesTextClassifierAccuracy prediction accuracy - unbalanced dataset: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Using a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank u @apple I can now compile all of the pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Finally! Brooklyn Is Getting Its Own #Apple St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RT @SwiftKey: We're so excited to be named to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  sentiment\n",
       "2   Thank u @apple I can now compile all of the pi...          1\n",
       "33  Finally! Brooklyn Is Getting Its Own #Apple St...          1\n",
       "34  RT @SwiftKey: We're so excited to be named to ...          1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 143 samples with 'positive' sentiment class\n",
    "positive_tweets = data.loc[data['sentiment'] == 1]\n",
    "print(positive_tweets.shape)\n",
    "positive_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>@Apple yo this Genius Bar shit is worst than t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>Hey @apple how about you guys make a charger t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>All of my apple product chargers look like tha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "757   @Apple yo this Genius Bar shit is worst than t...         -1\n",
       "1544  Hey @apple how about you guys make a charger t...         -1\n",
       "707   All of my apple product chargers look like tha...         -1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting 143 samples at random form 'negative' sentiment class\n",
    "negative_tweets = data.loc[data['sentiment'] == -1].sample(n=143, random_state=999)\n",
    "print(negative_tweets.shape)\n",
    "negative_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Is Apple The Most Important Stock On Earth?  h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Steve Wozniak calls @Apple's legendary garage ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>5 Companies Growing Faster Than Apple Inc. htt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "63    Is Apple The Most Important Stock On Earth?  h...          0\n",
       "944   Steve Wozniak calls @Apple's legendary garage ...          0\n",
       "1551  5 Companies Growing Faster Than Apple Inc. htt...          0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting 143 samples at random form 'neutral' sentiment class\n",
    "neutral_tweets = data.loc[data['sentiment'] == 0].sample(n=143, random_state=999)\n",
    "print(neutral_tweets.shape)\n",
    "neutral_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    143\n",
       "-1    143\n",
       " 0    143\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced = pd.concat([positive_tweets, negative_tweets, neutral_tweets])\n",
    "data_balanced['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1) (129, 1) (300,) (129,)\n"
     ]
    }
   ],
   "source": [
    "# Setting X and y\n",
    "X_b = data_balanced[['text']]\n",
    "\n",
    "y_b = data_balanced['sentiment']\n",
    "\n",
    "# Train, test split\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_b, y_b, test_size=0.3, random_state=999)\n",
    "\n",
    "print(X_train_b.shape, X_test_b.shape, y_train_b.shape, y_test_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset and drop indexes\n",
    "X_train_b.reset_index(drop=True, inplace=True)\n",
    "X_test_b.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning X_train\n",
    "X_train_cleaned_b = data_clean(X_train_b)\n",
    "\n",
    "# Converting X_train_cleaned and y_train to Numpy arrays\n",
    "X_train_cleaned_np_b = (X_train_cleaned_b.iloc[:,[0]].values).reshape((-1,))\n",
    "y_train_np_b = y_train_b.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training NaiveBayesTextClassifier\n",
    "nb_b = NaiveBayesTextClassifier()\n",
    "nb_b.fit(X_train_cleaned_np_b, y_train_np_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning X_test\n",
    "X_test_cleaned_b = data_clean(X_test_b)\n",
    "\n",
    "# Converting X_train_cleaned and y_train to Numpy arrays\n",
    "X_test_cleaned_np_b = (X_test_cleaned_b.iloc[:,[0]].values).reshape((-1,))\n",
    "y_test_np_b = y_test_b.to_numpy()\n",
    "\n",
    "# Predictions for X_test\n",
    "y_predict_b = nb_b.predict(X_test_cleaned_np_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayesTextClassifierAccuracy prediction accuracy - balanced dataset:  0.6976744186046512\n"
     ]
    }
   ],
   "source": [
    "test_acc_b = getNaiveBayesTextClassifierAccuracy(y_test_np_b, y_predict_b)\n",
    "print(\"NaiveBayesTextClassifierAccuracy prediction accuracy - balanced dataset: \", test_acc_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "- Following are the steps I followed in this exercise to implement a Naive Bayes Classifier for text classification\n",
    "\n",
    "**Load and analyze the dataset**\n",
    "- Once the CSV file is loaded and a basic analysis was done to check for null values etc. The dataset has two columns out of which X is set to column `text` and y is set to column `sentiment`, since the target of this exercise is to predict sentiment of a given tweet(text).\n",
    "- When I analyzed the dataset it was clear that the dataset is unbalanced.\n",
    "\n",
    "| Class  |  No. of samples |\n",
    "| :----: | --- |\n",
    "| Positive Sentiment (1) | 143 |\n",
    "|  Neutral Sentiment (0)| 801 |\n",
    "| Negative Sentiment (-1) | 686 |\n",
    "\n",
    "- In the first training (Experiment 1) I used the entire dataset and in the 2nd training (Experiment 2) I used a balanced dataset by selecting 143 samples from each class.\n",
    "- In both experiments steps I followed are described below.\n",
    "\n",
    "\n",
    "**Train test split**\n",
    "- 70% of the samples were used in training and 30% were used in testing accuracy of the model\n",
    "\n",
    "**Cleaning the X dataset**\n",
    "- The function `data_clean()` above clean `text` in several steps.\n",
    "    - Since tweets contain a lot of Twitter handles starting with '@' all such words were removed.\n",
    "    - Next, all words were converted to lowercase.\n",
    "    - URLs starting with http, words starting with \\'#\\', \\'$\\' were removed.\n",
    "    - Since tweets contain the phrase 'RT' to indicate re-tweets phrase 'RT' was removed.\n",
    "    - Commonly used stopwords like ‘and’, ‘the’, and ‘at’ that do not hold any special meaning in a sentence are also removed using Python Natural Language Toolkit(nltk)'s English stopwords list.\n",
    "    - Basically, the dataset is cleaned such that only words and space are remaining.\n",
    "\n",
    "**Implement `NaiveBayesTextClassifier` class**\n",
    "- The frequency of some of the words was extremely low. Thus the probability values were very small. Multiplying many small probabilities together resulted in values that rounded down to zero, causing runtime errors. To fix this both in fit and predict functions log-likelihoods were computed instead of likelihoods\n",
    "- Also to deal with words that do not appear in a specific class of the training data, thus causing a class-conditional probability of 0, Laplace smoothing was used.\n",
    "\n",
    "**Model training and prediction**\n",
    "- Using `data_clean()` function, tweets in training dataset were cleaned. The model was trained using the cleaned dataset.\n",
    "- Then tweets in X_test were also cleaned using `data_clean()` function and predicted values for `sentiment` were obtained for cleaned X_test.\n",
    "\n",
    "**Model accuracy**\n",
    "- Model accuracy comparison:\n",
    "\n",
    "| Experiment  |  Accuracy |\n",
    "| :----: | --- |\n",
    "| Model Trained using entire dataset | 0.8077709611451943 |\n",
    "| Model Trained using a balanced dataset | 0.6976744186046512 |\n",
    "\n",
    "- Even though the `NaiveBayesTextClassifier` I developed results in an accuracy of 0.8077709611451943 when trained using the entire dataset, its accuracy drops to 0.6976744186046512 when the training is done using a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
